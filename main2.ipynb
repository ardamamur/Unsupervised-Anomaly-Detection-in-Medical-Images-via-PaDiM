{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import wide_resnet50_2, resnet18\n",
    "from fast_ixi import FAST_IXI\n",
    "from utils import read_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# device setup\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'ann_path': '/home/mamur/TUM/Seminar/data/splits',\n",
       "  'path': '/home/mamur/TUM/Seminar/data',\n",
       "  'name': 'fast_ixi',\n",
       "  'resize': 128,\n",
       "  'cropsize': 128,\n",
       "  'batch_size': 1},\n",
       " 'model': {'backbone': 'wide_resnet50_2'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = read_config('config.yaml')\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import DataHandler\n",
    "processor = DataHandler(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mass_all_neg.csv', 'posttreatment.csv', 'wml_ann.csv', 'edema_neg.csv', 'ixi_normal_train.csv', 'posttreatment_neg.csv', 'intraventricular_neg.csv', 'artefacts_ann.csv', 'lesions.csv', 'normal_train.csv', 'dural_ann.csv', 'mass_all.csv', 'intraventricular.csv', 'normal_val.csv', 'enlarged_ventricles_ann.csv', 'encephalomalacia.csv', 'resection_neg.csv', 'sinus_ann.csv', 'normal_test.csv', 'absent_septum.csv', 'wml_neg.csv', 'mass.csv', 'artefacts_neg.csv', 'ea_mass_neg.csv', 'edema.csv', 'normal_test_ann.csv', 'craniatomy_ann.csv', 'other.csv', 'artefacts.csv', 'intraventricular_ann.csv', 'lesions_ann.csv', 'enlarged_ventricles_neg.csv', 'craniatomy.csv', 'mass_neg.csv', 'resection_ann.csv', 'wml.csv', 'mass_ann.csv', 'encephalomalacia_neg.csv', 'ea_mass.csv', 'dural.csv', 'posttreatment_ann.csv', 'local_neg.csv', 'other_ann.csv', 'lesions_neg.csv', 'edema_ann.csv', 'other_neg.csv', 'encephalomalacia_ann.csv', 'absent_septum_neg.csv', 'resection.csv', 'enlarged_ventricles.csv', 'sinus.csv', 'ea_mass_ann.csv', 'absent_septum_ann.csv', 'sinus_neg.csv', 'craniatomy_neg.csv', 'mass_all_ann.csv', 'dural_neg.csv', 'local.csv']\n",
      "mass_all\n",
      "posttreatment\n",
      "wml\n",
      "edema\n",
      "class already exists\n",
      "posttreatment\n",
      "intraventricular\n",
      "artefacts\n",
      "lesions\n",
      "normal_train.csv\n",
      "dural\n",
      "class already exists\n",
      "mass_all\n",
      "class already exists\n",
      "intraventricular\n",
      "normal_val.csv\n",
      "enlarged_ventricles\n",
      "encephalomalacia\n",
      "resection\n",
      "sinus\n",
      "normal_test.csv\n",
      "absent_septum\n",
      "class already exists\n",
      "wml\n",
      "mass\n",
      "class already exists\n",
      "artefacts\n",
      "ea_mass\n",
      "class already exists\n",
      "edema\n",
      "craniatomy\n",
      "other\n",
      "class already exists\n",
      "artefacts\n",
      "class already exists\n",
      "intraventricular\n",
      "class already exists\n",
      "lesions\n",
      "class already exists\n",
      "enlarged_ventricles\n",
      "class already exists\n",
      "craniatomy\n",
      "class already exists\n",
      "mass\n",
      "class already exists\n",
      "resection\n",
      "class already exists\n",
      "wml\n",
      "class already exists\n",
      "mass\n",
      "class already exists\n",
      "encephalomalacia\n",
      "class already exists\n",
      "ea_mass\n",
      "class already exists\n",
      "dural\n",
      "class already exists\n",
      "posttreatment\n",
      "local\n",
      "class already exists\n",
      "other\n",
      "class already exists\n",
      "lesions\n",
      "class already exists\n",
      "edema\n",
      "class already exists\n",
      "other\n",
      "class already exists\n",
      "encephalomalacia\n",
      "class already exists\n",
      "absent_septum\n",
      "class already exists\n",
      "resection\n",
      "class already exists\n",
      "enlarged_ventricles\n",
      "class already exists\n",
      "sinus\n",
      "class already exists\n",
      "ea_mass\n",
      "class already exists\n",
      "absent_septum\n",
      "class already exists\n",
      "sinus\n",
      "class already exists\n",
      "craniatomy\n",
      "class already exists\n",
      "mass_all\n",
      "class already exists\n",
      "dural\n",
      "class already exists\n",
      "local\n"
     ]
    }
   ],
   "source": [
    "df = processor.create_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_map = df['full_map'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [00:00<00:00, 582270.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# check if all the paths in df['full_map'] are exist\n",
    "for path in tqdm(full_map):\n",
    "    if path is None:\n",
    "        continue\n",
    "    if not os.path.exists(path):\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
